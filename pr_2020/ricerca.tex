\documentclass[11pt,twoside,a4paper]{article}
\usepackage{graphicx} 
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{url}
\usepackage{amsmath}
\usepackage{cite}
\usepackage[T1]{fontenc}
\newcommand{\HRule}{\rule{\linewidth}{0.2mm}}
\thispagestyle{empty}
\setlength{\parindent}{0mm}
\setlength{\parskip}{0mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hoffset = -2.0 cm
\voffset = -3.0 cm
\textheight = 25.0 cm
\marginparwidth = 1.0 cm
\evensidemargin = 1.0 cm
\textwidth =16.1 cm
\renewcommand{\arraystretch}{1.5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% remove "References" title
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

La mia attivit\`a di ricerca \`e incentrata sulla fisica sperimentale
delle alte energie.

Dal 2002 al 2007 si \`e incentrata sullo studio della violazione della
simmetria CP nei decadimenti deboli del mesone $B$ e sulla ricerca di
segnali indiretti di fisica oltre il Modello Standard nel settore del
sapore, attraverso i decadimenti \textit{charmless} $b \to s$.  La
misura della violazione di CP dipendente dal tempo del mesone $B$ in
tre mesoni $K$, prima nell'approssimazione \textit{quasi due
  corpi}~\cite{Aubert:2008rr}, e infine includendo gli effetti di
interferenza attraverso l'analisi del Dalitz
plot~\cite{Aubert:2007sd,Aubert:2007me}. Attraverso questo studio si
\`e scoperta una nuova risonanza di spin zero, con una massa circa di
1.55 GeV/c$^2$, la $X_0(1550)$, che decade in due kaoni carichi. Per
questi studi si \`e dovuta sviluppare una tecnica di misura ad-hoc dei
vertici di decadimento dei mesoni $K^0_S$, usando il vincolo del punto
di interazione dei fasci $e^+e^-$ del collisore SLAC di
Stanford~\cite{Aubert:2005dy,Aubert:2005gj}.  Queste misure hanno
vincolato in modo significativo la presenza di processi non previsti
dal Modello Standard che producano violazione del sapore.  Ho
effettuato queste misure utilizzando i dati dell'esperimento $BaBar$,
collocato nel punto di interazione del collisore $e^+e^-$ al
laboratorio SLAC di Stanford (California).

Dal 2005 al 2006 sono stato \textit{operations manager} per gli studi
di performance per il rivelatore \textit{IFR} di BaBar basato sulla
tecnologia di RPC, necessario per la ricostruzione e identificazione
dei muoni e degli adroni neutri. In questo contesto ho personalmente
sviluppato algoritmi innovativi per la ricostruzione di $K^0_L$,
basati sull'applicazione di \textit{Boosted Decision Trees}, una delle
prime applicazioni di \textit{machine learning} nella fisica delle
alte energie, per la combinazione ottimale delle informazioni del
calorimetro elettromagnetico e dell'IFR. Durante questo periodo ho
anche effettuato lo studio delle possibili cause di invecchiamento
degli RPC a causa della produzione di acido fluoridrico nella miscela
di gas, e le soluzioni =permitigarne
l'effetto~\cite{Band:2008zza}. Con la loro applicazione, il rivelatore
ha mantenuto un'efficienza stabile attraverso il periodo rimanente di
presa dati, anche dopo il cambiamento di modalit\`a di operazione da
regime \textit{streamer} a
\textit{avalanche}~\cite{Band:2006ig,Anulli:2005wi}. Ho partecipato
all'upgrade del settore barrel dell'IFR da RPC a \textit{Limited
  Streamer Tubes}.

Dal 2005 al 2006 sono stato responsabile delle misure di efficienza
del \textit{$B$-flavour tagging} e della risoluzione di vertice, usate
dall'intera collaborazione BaBar per tutte le misure di violazione di
CP dipendenti dal tempo. Nel 2005 ho effettuato misure relative al
tracciamento di particelle cariche, all'interno della task force per
il recupero della perdita di efficienza di ricostruzione dei
$K^0_S$. Questo ha permesso di recuperare l'intera efficienza durante
lo shitdown temporaneo dell'acceleratore e prima del nuovo periodo di
presa dati.

Dal 2007 sono collaboratore dell'esperimento CMS presso il Large
Hadron Collider di Ginevra, e sono stato coinvolto in numerose
attivit\`a sperimentali sul rivelatore e di analisi dei dati. Dal 2007
al 2010 ho partecipato al \textit{commissioning} del sistema che
fornisce l'alta tensione agli avalanche photodiodes (APD) del
calorimetro elettromagnetico (ECAL). Nello stesso periodo ho anche
sviluppato il data-quality-monitoring (DQM) di ECAL, che \`e ancora in
uso, in gran parte nell'implementazione
originale~\cite{DiMarco:2009zz}. Inoltre, dal 2011 al 2014 sono stato
responsabile del sistema hardware con il laser, usato per il
monitoring costante e frequente delle variazioni di trasparenza,
dovute all'irraggiamento durante i fill di LHC.

Con i primissimi dati forniti da LHC all'esperimento CMS (36 pb$^{-1}$
a un'energia $\sqrt{s}$=7\,TeV) sono stato l'autore principale della
prima misura di sezione d'urto di produzione di bosoni W e Z,
inclusiva e differenziale,in funzione del numero di jet adronici
associati~\cite{Chatrchyan:2011ne,Marco:2009dvd,Khachatryan:2010xn,CMS:2011aa}.
Con gli stessi dati \`e stato possibile effettuare la prima misura
differenziale dell'asimmetria di carica del bosone W, utile per
vincolare le PDF del protone nei range di momento esplorati da
LHC~\cite{Chatrchyan:2011jz}.

Dal 2008 sono stato uno degli sviluppatori della ricostruzione di
elettroni di CMS~\cite{Khachatryan:2015hwa}, che ha permesso tutte le
misure sui bosoni elettrodeboli W e Z, e le primissime ricerche del
bosone di Higgs nei canali di decadimento pi\`u puri, WW e ZZ negli
stati finali completamente leptonici. Dal 2013 al 2014 sono stato il
responsabile del sottogruppo di \textit{EGamma} per la ricostruzione e
l'identificazione di elettroni e fotoni di CMS.

Fin dall'inizio dell'attivit\`a in CMS sono stato coinvolto nella
ricerca diretta del bosone di Higgs del Modello
Standard~\cite{Chatrchyan:2011tz,Chatrchyan:2012tx,Chatrchyan:2012ty}. In
questo contesto, dal 2011 al 2012 sono stato il coordinatore del
gruppo di analisi per la ricerca del bosone di Higgs in coppie di
bosoni W, analisi che ha dato la prima indicazione della particella di
massa intorno a 125 GeV, e ha contribuito, assieme agli altri canali
principali, alla sua
scoperta~\cite{Chatrchyan:2012ufa,Chatrchyan:2013lba}. Ho presentato
personalmente i risultati della ricerca con i dati di Run1 di LHC alla
conferenza internazionale ICHEP 2012 di Melbourne. Ho anche proposto e
applicato un metodo di analisi che permette una stima della massa di
una risonanza che decade in uno stato finale con due neutrini: nel
caso di H$\to$WW permette una risoluzione di massa del
3\%~\cite{Chatrchyan:2013iaa}, che non \`e competitivo con gli stati
finali $\gamma\gamma$ e 4 leptoni carichi (ZZ), ma pu\`o, ed \`e stato
usato per ricerche di particelle supersimmetriche con catene di
decadimento complesse~\cite{Khachatryan:2016epu}. Allo stesso tempo ho
misurato la sezione d'urto di produzione inclusiva di coppie di bosoni
W a $\sqrt{s}$=7 e 8 TeV~\cite{Chatrchyan:2013yaa}.

Sono stato anche uno degli autori principali ed editor dell'articolo
\textit{legacy} di Run1 per la ricerca del bosone di Higgs nel canale
di decadimento $ZZ\to4\ell$ e riguardante le misure effettuate,
riguardo la massa e le propriet\`a di spin-CP del bosone
scoperto~\cite{Chatrchyan:2013mxa}. Ho coordinato il gruppo di analisi
di questo canale di decadimento con i dati di Run1 dal 2013 al
2014~\cite{Khachatryan:2014kca}. Ho sviluppato la tecnica di analisi
per effettuare l'unfolding dei parametri di accoppiamento effettivi
del bosone di Higgs attraverso un fit simultaneo 8-dimensionale al set
completo di variabili cinematiche del decadimento in 4 leptoni,
collaborando con un gruppo di fisici teorici~\cite{Chen:2014pia}.

Dal 2014 al 2017 sono stato il coordinatore del gruppo di performance
del calorimetro elettromagnetico di CMS (DPG), che implica la
responsabilit\`a dell'ottimizzazione delle condizioni di presa dati,
ricostruzione e calibrazione dei depositi di
energia~\cite{Khachatryan:2015iwa}. Durante questo periodo ho coperto
la transizione dal Run1 al Run2, quando la spaziatura temporale tra i
bunch di protoni LHC \`e cambiata da 50 a 25\,ns. Nel 2014 ho
sviluppato un algoritmo di ricostruzione dell'ampiezza del segnale
digitizzato in ECAL totalmente innovativo, chiamato \textit{multifit},
e basato sul fit simultaneo di segnali di bunch-crossings diversi che
si sovrappongono nell'intervallo di tempo della digitizzazione.
Questo permette di azzerare il peggioramento di risoluzione energetica
dovuto al pileup di eventi di bunch crossings vicini a quello
nominale.  Questa tecnica, sviluppata durante lo shutdown tra Run1 e
Run2, \`e stata applicata lungo tutto il corso di Run2, ed estesa
dalla ricostruzione offline anche al trigger di alto livello nel 2016.
Essa ha permesso di far rimanere inalterata la risoluzione in energia
di ECAL per gli effetti dovuti al pileup. La stessa tecnica \`e
prevista di essere usata per la fase di alta luminosit\`a di LHC, e il
suo funzionamento \`e stato dimostrato fino a una media di eventi di
pileup di 200 per collisione.





\bibliographystyle{habbrvyr} % reverse cronological order using habbrvyr.bst
\bibliography{INSPIRE-CiteAll-2004-2019}

\end{document}
